Running Subgraph Mamba on dataset: ppi_bp
/home/gridsan/yzhu/AM220/SubgraphMamba/dataset.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  y = torch.tensor(self.subgraph_labels[idx], dtype=torch.long)
Freezing Mamba layers to compare performance
Current date and time: 2024-04-11 15:26:44.576201
{'dataset_name': 'ppi_bp', 'learning_rate': 0.0005, 'weight_decay': 0.01, 'batch_size': 32, 'epochs': 50, 'patience': 100, 'hidden_dim': 16, 'mamba_dim': 16, 'seqlength': 3000, 'hops': 2, 'num_classes': 6, 'multilabel': False, 'embeddings_filename': 'graphsaint_gcn_embeddings.pth'}
[9339]
{'metabolism': 0, 'development': 1, 'signal_transduction': 2, 'stress_death': 3, 'cell_org': 4, 'transport': 5}
Epoch: 0001 loss_train: 70.5487 acc_train: 0.2028 acc_val: 0.2687
Epoch: 0002 loss_train: 69.3560 acc_train: 0.2429 acc_val: 0.2562
Epoch: 0003 loss_train: 68.4653 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0004 loss_train: 68.0072 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0005 loss_train: 67.8348 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0006 loss_train: 67.8158 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0007 loss_train: 67.7799 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0008 loss_train: 67.7262 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0009 loss_train: 67.7206 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0010 loss_train: 67.7079 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0011 loss_train: 67.6961 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0012 loss_train: 67.6996 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0013 loss_train: 67.6489 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0014 loss_train: 67.7456 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0015 loss_train: 67.6839 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0016 loss_train: 67.6721 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0017 loss_train: 67.7170 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0018 loss_train: 67.6953 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0019 loss_train: 67.6961 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0020 loss_train: 67.6378 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0021 loss_train: 67.6747 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0022 loss_train: 67.6111 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0023 loss_train: 67.5740 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0024 loss_train: 67.6695 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0025 loss_train: 67.5990 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0026 loss_train: 67.5902 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0027 loss_train: 67.6154 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0028 loss_train: 67.5862 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0029 loss_train: 67.5309 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0030 loss_train: 67.6089 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0031 loss_train: 67.5775 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0032 loss_train: 67.5677 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0033 loss_train: 67.5191 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0034 loss_train: 67.5026 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0035 loss_train: 67.4991 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0036 loss_train: 67.4590 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0037 loss_train: 67.4947 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0038 loss_train: 67.4952 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0039 loss_train: 67.4687 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0040 loss_train: 67.4750 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0041 loss_train: 67.4447 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0042 loss_train: 67.4479 acc_train: 0.3050 acc_val: 0.2562
Epoch: 0043 loss_train: 67.3622 acc_train: 0.3042 acc_val: 0.2562
Epoch: 0044 loss_train: 67.3971 acc_train: 0.3042 acc_val: 0.2562
Epoch: 0045 loss_train: 67.3312 acc_train: 0.3042 acc_val: 0.2562
Epoch: 0046 loss_train: 67.3406 acc_train: 0.3042 acc_val: 0.2562
Epoch: 0047 loss_train: 67.3598 acc_train: 0.3042 acc_val: 0.2562
Epoch: 0048 loss_train: 67.3622 acc_train: 0.3042 acc_val: 0.2562
Epoch: 0049 loss_train: 67.3241 acc_train: 0.3035 acc_val: 0.2562
Epoch: 0050 loss_train: 67.3160 acc_train: 0.3035 acc_val: 0.2562
Optimization Finished! Total time elapsed: 370.556387
