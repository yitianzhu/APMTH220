04/08 a
Learning rate of 0.01 is WAY TOO LARGE, loss starts increasing. 
Learning rate of 0.001 works but it can be a bit slow. 
Accuracy is also not strictly increasing, could be sign of instability. 
Next time I should try LR 0.0005 and LR 0.005 at 15 epochs. 

04/08 b
Learning rate 0.005 doesn't work; for some reason it just stays at the same loss after each epoch 
Learning rate 0.0005 is okay but we see some instability. Might have to do with batch size. 
Next time I will try batch size of 35 for both train and val. 

04/08 c
Training accuracy rarely exceeds random guessing, validation accuracy is all over the place 
Need to look back at graph mamba and see how they did their architecture 
Also we are stuck at 0 hops right now aka it's just graph mamba block on subgraphs. 

04/08 d
I just incorporated the skip connection and the mean by inclusion (higher degree nodes will be weighted more)
batch size matters! when batch size was 32 nothing happened... well loss increased a bit. 
I changed it to batch size 20 and it started learning. also i decreased LR to 0.0001 
nothing is looking hot, so i changed the hidden dimension to 64. also did not work 
Trying to use 2 mamba layers instead of 1 

04/09 a
Need more subgraphs in the dataset. 
Let's try hpo_neuro and hpo_metab which have like 3000 and 2000 subgraphs in the dataset as opposed to 200 
Ah frick it's monthly downtime smh I am convinced that the computing cluster is a female
802 hpo_metab
Note that 6 classes for hpo_metab - dict_keys(['Lysosomal', 'Energy', 'Amino_Acid', 'Carbohydrate', 'Lipid', 'Glycosylation'])
Let's try HPO_metab 50 epochs at lr 0.01 0.001 

04/11 a 
Tried LR of 0.0005 for all three datasets but it seems like there's similar behavior where it's not learning really well.
A few things to try 
* ablation: freeze the mamba block layers and see if it still trains. 
* permutation: randomly order the subgraphs and their neighbors in like 50 different ways as data augmentation 
UPDATE: ABLATION SHOWS MAMBA AINT DOING SHIT -- same results as freezing. kinda confused
UPDATE: AUGMENT IS HELPING?!??!

04/11 b
Augmenting by generating slightly perturbed sequences for mamba to take in
(aka just randomized within nodes of same degree and changing order of the subgraph)
Learning is slightly faster, but we should figure out if we credit Mamba for it.
Trying one with frozen Mamba layers to see if it helps. 
OK SO after 50 epochs at LR 0.0005 the linear only did kinda bad on training accuracy while mamba did better (0.3 vs 0.4)
BUT unfortunately they are very much overfit, validation ends up being 0.25 ish and quite unstable 

04/11 c
(1) Apply batch normalization, dropout, and skip connections. see Janus code for inspiration 
if (1) doesnt work then (2) train for some epochs then freeze all layers except for Mamba. 
Ok nevermind, (1) does work. \

here's the takeaways for hpo_metab
* Mamba does help (1 mamba layer vs frozen mamba weights) (66% vs 36% training) 
* More mamba layers makes huge difference (1 vs 2 vs 4 mamba layers) (66% vs 90% vs 100% training)
* zero-one labeling seems to help a bit? (no label vs label) (63% vs 66%)
* code failed for no concatentation, my bad
* base GCN layer is needed, (no gcn vs gcn) (48.9% vs 66%)
PROBLEM: totally overfitting to training data. I never got above 30% validation!

here's the takeaways for hpo_neuro 
* increasing layers helps training but hurts validation scores. mamba layers (1 2 4) train (84% 88% 95%) val (79% 75% 73%)
* mamba makes a difference though: if you freeze mamba layers training accuracy doesnt change (79% to 80%). final trainig accuracy (no mamba vs mamba) (80% vs 84%)
* zero-one labeling doesn't seem to help much
PROBLEM: overfitting here too! 
